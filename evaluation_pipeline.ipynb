{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb536713",
   "metadata": {},
   "source": [
    "# Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c55608a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "DATABASE CONNECTION TEST\n",
      "================================================================================\n",
      "Connected to system-llm-postgres-local\n",
      "Version: PostgreSQL 15.15 (Debian 15.15-1.pgdg12+1) on x86_64-pc-linux-gnu\n",
      "\n",
      "âœ“ Environment loaded\n",
      "âœ“ OpenAI API: Ready\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import asyncio\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any, Optional\n",
    "from datetime import datetime\n",
    "from dataclasses import dataclass, asdict\n",
    "import numpy as np\n",
    "\n",
    "# Add backend to path\n",
    "sys.path.insert(0, str(Path.cwd()))\n",
    "\n",
    "# Load environment\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv('.env.local')\n",
    "\n",
    "# Metrics imports\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "try:\n",
    "    from rouge_score import rouge_scorer\n",
    "except ImportError:\n",
    "    print(\"âš  rouge_score not installed. Run: pip install rouge-score\")\n",
    "\n",
    "try:\n",
    "    from nltk.translate.meteor_score import meteor_score\n",
    "except ImportError:\n",
    "    print(\"âš  METEOR requires NLTK meteor scorer\")\n",
    "\n",
    "try:\n",
    "    from bert_score import score as bert_score_fn\n",
    "except ImportError:\n",
    "    print(\"âš  bert_score not installed. Run: pip install bert-score\")\n",
    "\n",
    "try:\n",
    "    from openai import OpenAI\n",
    "except ImportError:\n",
    "    print(\"âš  openai not installed. Run: pip install openai\")\n",
    "\n",
    "# Download NLTK data if needed\n",
    "try:\n",
    "    import nltk\n",
    "    nltk.data.find('tokenizers/punkt')\n",
    "except LookupError:\n",
    "    print(\"Downloading NLTK data...\")\n",
    "    nltk.download('punkt', quiet=True)\n",
    "    nltk.download('wordnet', quiet=True)\n",
    "\n",
    "# ============================================================================\n",
    "# ðŸ”Œ DATABASE CONNECTION (via docker-compose exec) - SAMA SEPERTI rag_document_pipeline.ipynb\n",
    "# ============================================================================\n",
    "\n",
    "class DatabaseConnection:\n",
    "    \"\"\"Docker PostgreSQL connection via docker-compose exec with stdin\"\"\"\n",
    "    def __init__(self, working_dir: str = \".\"):\n",
    "        self.working_dir = working_dir\n",
    "        self.container_name = \"system-llm-postgres-local\"\n",
    "        self.user = \"llm_user\"\n",
    "        self.db = \"system_llm\"\n",
    "\n",
    "    def execute_sql(self, query: str, fetch: bool = False) -> str:\n",
    "        \"\"\"Execute SQL via docker-compose exec with stdin (handles long queries)\"\"\"\n",
    "        cmd = [\n",
    "            \"docker-compose\", \"-f\", \"docker-compose.local.yml\",\n",
    "            \"exec\", \"-T\", \"postgres\",\n",
    "            \"psql\", \"-U\", self.user, \"-d\", self.db,\n",
    "        ]\n",
    "        \n",
    "        if fetch:\n",
    "            cmd.append(\"-t\")\n",
    "\n",
    "        try:\n",
    "            result = subprocess.run(\n",
    "                cmd,\n",
    "                input=query,\n",
    "                capture_output=True,\n",
    "                text=True,\n",
    "                encoding='utf-8',\n",
    "                errors='replace',\n",
    "                cwd=self.working_dir\n",
    "            )\n",
    "\n",
    "            if result.returncode != 0:\n",
    "                error_msg = result.stderr.strip() if result.stderr else \"Unknown error\"\n",
    "                raise Exception(f\"SQL Error: {error_msg}\")\n",
    "\n",
    "            return result.stdout.strip() if fetch else \"\"\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Database Error: {e}\")\n",
    "            raise\n",
    "\n",
    "    def test_connection(self) -> bool:\n",
    "        \"\"\"Test database connection\"\"\"\n",
    "        try:\n",
    "            version = self.execute_sql(\"SELECT version();\", fetch=True)\n",
    "            if version:\n",
    "                db_version = version.split(',')[0].strip()\n",
    "                print(f\"Connected to {self.container_name}\")\n",
    "                print(f\"Version: {db_version}\\n\")\n",
    "                return True\n",
    "        except Exception as e:\n",
    "            print(f\"Connection failed: {e}\\n\")\n",
    "            return False\n",
    "\n",
    "# Initialize database\n",
    "db = DatabaseConnection(working_dir=\".\")\n",
    "print(\"=\" * 80)\n",
    "print(\"DATABASE CONNECTION TEST\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "if not db.test_connection():\n",
    "    sys.exit(1)\n",
    "\n",
    "# OpenAI client\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "if not OPENAI_API_KEY:\n",
    "    print(\"ERROR: OPENAI_API_KEY not set in .env.local\")\n",
    "    sys.exit(1)\n",
    "\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "print(\"âœ“ Environment loaded\")\n",
    "print(f\"âœ“ OpenAI API: Ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef6c5c0",
   "metadata": {},
   "source": [
    "# List Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d23d973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š Available Models:\n",
      "======================================================================\n",
      "0. gpt-4.1-nano                   | Provider: OPENAI         \n",
      "1. claude-haiku-4-5               | Provider: ANTHROPIC      \n",
      "2. gemini-2.5-flash               | Provider: GOOGLE         \n",
      "10. meta-llama/llama-3.1-8b-instruct | Provider: openrouter     \n",
      "11. qwen/qwen-2.5-7b-instruct      | Provider: openrouter     \n",
      "12. microsoft/phi-3-medium-128k-instruct | Provider: openrouter     \n",
      "======================================================================\n",
      "Total: 6 models\n",
      "\n",
      "âœ“ Models loaded. Using default: gpt-4.1-nano\n"
     ]
    }
   ],
   "source": [
    "def list_models() -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Query database for available models.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        query = \"\"\"\n",
    "        SELECT id, name, provider, \"order\" \n",
    "        FROM model \n",
    "        ORDER BY \"order\" ASC;\n",
    "        \"\"\"\n",
    "        result = db.execute_sql(query, fetch=True)\n",
    "        \n",
    "        model_list = []\n",
    "        print(f\"\\nðŸ“Š Available Models:\")\n",
    "        print(\"=\" * 70)\n",
    "        \n",
    "        if result:\n",
    "            for line in result.split('\\n'):\n",
    "                if '|' in line and not line.startswith('-'):\n",
    "                    parts = line.split('|')\n",
    "                    if len(parts) >= 4:\n",
    "                        try:\n",
    "                            model_id = parts[0].strip()\n",
    "                            name = parts[1].strip()\n",
    "                            provider = parts[2].strip()\n",
    "                            order = parts[3].strip()\n",
    "                            \n",
    "                            if model_id and name:\n",
    "                                model_info = {\n",
    "                                    \"id\": model_id,\n",
    "                                    \"name\": name,\n",
    "                                    \"provider\": provider,\n",
    "                                    \"order\": order,\n",
    "                                }\n",
    "                                model_list.append(model_info)\n",
    "                                print(f\"{order}. {name:30} | Provider: {provider:15}\")\n",
    "                        except:\n",
    "                            pass\n",
    "        \n",
    "        print(\"=\" * 70)\n",
    "        if model_list:\n",
    "            print(f\"Total: {len(model_list)} models\\n\")\n",
    "        return model_list\n",
    "    except Exception as e:\n",
    "        print(f\"Error listing models: {e}\")\n",
    "        return []\n",
    "\n",
    "# List available models\n",
    "available_models = list_models()\n",
    "if available_models:\n",
    "    print(f\"âœ“ Models loaded. Using default: {available_models[0]['name']}\")\n",
    "else:\n",
    "    print(\"âœ— No models found in database\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ba1d84",
   "metadata": {},
   "source": [
    "# EvaluationChatService"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7ffe39c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ EvaluationChatService ready (with fixed refine_prompt execution)\n"
     ]
    }
   ],
   "source": [
    "@dataclass\n",
    "class EvaluationConfig:\n",
    "    \"\"\"Configuration for evaluation run - matches ChatSession fields.\"\"\"\n",
    "    model_name: str = \"gpt-4.1-nano\"\n",
    "    use_tools: bool = True\n",
    "    with_rag: bool = True\n",
    "    max_tool_iterations: int = 3\n",
    "    temperature: float = 0.7\n",
    "    \n",
    "    # Override fields (like ChatSession can override per-session)\n",
    "    prompt_general_override: Optional[str] = None\n",
    "    task_override: Optional[str] = None\n",
    "    persona_override: Optional[str] = None\n",
    "    mission_objective_override: Optional[str] = None\n",
    "    prompt_id_override: Optional[str] = None\n",
    "\n",
    "# ============================================================================\n",
    "# Helper Functions - Load from Database (matches production)\n",
    "# ============================================================================\n",
    "\n",
    "def get_chat_config() -> Dict[str, Any]:\n",
    "    \"\"\"Get ChatConfig singleton from database (id=1).\"\"\"\n",
    "    try:\n",
    "        query = \"\"\"\n",
    "        SELECT id, prompt_general, prompt_refine, prompt_analysis, \n",
    "               default_top_k, max_top_k, similarity_threshold,\n",
    "               tool_calling_max_iterations, tool_calling_enabled,\n",
    "               include_rag_instruction\n",
    "        FROM chat_config WHERE id = 1;\n",
    "        \"\"\"\n",
    "        result = db.execute_sql(query, fetch=True)\n",
    "        \n",
    "        if result:\n",
    "            # Parse psql output\n",
    "            for line in result.split('\\n'):\n",
    "                if '|' in line and not line.startswith('-'):\n",
    "                    parts = line.split('|')\n",
    "                    if len(parts) >= 10:\n",
    "                        return {\n",
    "                            \"id\": parts[0].strip(),\n",
    "                            \"prompt_general\": parts[1].strip() if parts[1].strip() != \"\" else None,\n",
    "                            \"prompt_refine\": parts[2].strip() if parts[2].strip() != \"\" else None,\n",
    "                            \"prompt_analysis\": parts[3].strip() if parts[3].strip() != \"\" else None,\n",
    "                            \"default_top_k\": int(parts[4].strip()) if parts[4].strip() else 5,\n",
    "                            \"max_top_k\": int(parts[5].strip()) if parts[5].strip() else 10,\n",
    "                            \"similarity_threshold\": float(parts[6].strip()) if parts[6].strip() else 0.7,\n",
    "                            \"tool_calling_max_iterations\": int(parts[7].strip()) if parts[7].strip() else 10,\n",
    "                            \"tool_calling_enabled\": bool(int(parts[8].strip())) if parts[8].strip() else True,\n",
    "                            \"include_rag_instruction\": bool(int(parts[9].strip())) if parts[9].strip() else True,\n",
    "                        }\n",
    "        \n",
    "        # Return defaults if not found\n",
    "        return {\n",
    "            \"id\": \"1\",\n",
    "            \"prompt_general\": None,\n",
    "            \"prompt_refine\": \"Refine the student's question to be more specific and clear for better search results.\",\n",
    "            \"prompt_analysis\": None,\n",
    "            \"default_top_k\": 5,\n",
    "            \"max_top_k\": 10,\n",
    "            \"similarity_threshold\": 0.7,\n",
    "            \"tool_calling_max_iterations\": 10,\n",
    "            \"tool_calling_enabled\": True,\n",
    "            \"include_rag_instruction\": True,\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Could not get ChatConfig from DB: {e}\")\n",
    "        return {\n",
    "            \"prompt_general\": None,\n",
    "            \"prompt_refine\": \"Refine the student's question to be more specific and clear.\",\n",
    "            \"prompt_analysis\": None,\n",
    "            \"default_top_k\": 5,\n",
    "            \"max_top_k\": 10,\n",
    "            \"similarity_threshold\": 0.7,\n",
    "            \"tool_calling_max_iterations\": 10,\n",
    "            \"tool_calling_enabled\": True,\n",
    "            \"include_rag_instruction\": True,\n",
    "        }\n",
    "\n",
    "def get_prompt_content(prompt_id: str) -> Optional[str]:\n",
    "    \"\"\"Get prompt content from Prompt table.\"\"\"\n",
    "    try:\n",
    "        query = f\"SELECT content FROM prompt WHERE id = '{prompt_id}' LIMIT 1;\"\n",
    "        result = db.execute_sql(query, fetch=True)\n",
    "        \n",
    "        if result:\n",
    "            for line in result.split('\\n'):\n",
    "                if line and not line.startswith('-'):\n",
    "                    return line.strip()\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Could not get prompt from DB: {e}\")\n",
    "        return None\n",
    "\n",
    "def generate_embedding(text: str) -> List[float]:\n",
    "    \"\"\"Generate 1536-dimensional embedding\"\"\"\n",
    "    response = client.embeddings.create(\n",
    "        input=text,\n",
    "        model=\"text-embedding-3-small\"\n",
    "    )\n",
    "    return response.data[0].embedding\n",
    "\n",
    "def semantic_search(query_text: str, top_k: int = 5) -> list:\n",
    "    \"\"\"Semantic search using cosine similarity dengan database\"\"\"\n",
    "    try:\n",
    "        # Generate query embedding\n",
    "        query_embedding = np.array(generate_embedding(query_text))\n",
    "        \n",
    "        # Get chunks from database via SQL (matches production query)\n",
    "        search_query = \"\"\"\n",
    "        SELECT dc.content, d.original_filename, dc.page_number, dc.embedding\n",
    "        FROM document_chunk dc\n",
    "        JOIN document d ON dc.document_id = d.id\n",
    "        WHERE d.status = 'PROCESSED'\n",
    "        LIMIT 100;\n",
    "        \"\"\"\n",
    "        result_text = db.execute_sql(search_query, fetch=True)\n",
    "        \n",
    "        similarities = []\n",
    "        if result_text:\n",
    "            for line in result_text.split('\\n'):\n",
    "                if '|' in line:\n",
    "                    parts = line.split('|', 3)\n",
    "                    if len(parts) >= 4:\n",
    "                        try:\n",
    "                            content = parts[0].strip()\n",
    "                            filename = parts[1].strip()\n",
    "                            page_num = int(parts[2].strip()) if parts[2].strip().isdigit() else 0\n",
    "                            embedding_json = parts[3].strip()\n",
    "                            \n",
    "                            if embedding_json.startswith('['):\n",
    "                                chunk_embedding = np.array(json.loads(embedding_json))\n",
    "                                similarity = np.dot(query_embedding, chunk_embedding) / (\n",
    "                                    np.linalg.norm(query_embedding) * np.linalg.norm(chunk_embedding) + 1e-10\n",
    "                                )\n",
    "                                similarities.append({\n",
    "                                    \"content\": content[:500],\n",
    "                                    \"original_filename\": filename,\n",
    "                                    \"page_number\": page_num,\n",
    "                                    \"similarity_score\": float(similarity)\n",
    "                                })\n",
    "                        except:\n",
    "                            pass\n",
    "        \n",
    "        similarities.sort(key=lambda x: x['similarity_score'], reverse=True)\n",
    "        return similarities[:top_k]\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Semantic search error: {e}\")\n",
    "        return []\n",
    "\n",
    "class EvaluationChatService:\n",
    "    \"\"\"\n",
    "    Chat service for evaluation - mengikuti arsitektur ChatService asli\n",
    "    dengan proper refine_prompt dan semantic_search implementation\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.chat_config = get_chat_config()\n",
    "    \n",
    "    def _get_tools(self) -> List[Dict[str, Any]]:\n",
    "        \"\"\"Get available tools for the chat (matches production order).\"\"\"\n",
    "        return [\n",
    "            {\n",
    "                \"name\": \"refine_prompt\",\n",
    "                \"description\": \"Refine and clarify an ambiguous or unclear student question. Use this tool when the student's question is vague, incomplete, or could be interpreted multiple ways.\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"original_prompt\": {\"type\": \"string\", \"description\": \"The original student question that needs refinement/clarification\"},\n",
    "                    },\n",
    "                    \"required\": [\"original_prompt\"]\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"semantic_search\",\n",
    "                \"description\": \"Search for relevant documents based on semantic similarity\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"query\": {\"type\": \"string\", \"description\": \"Search query\"},\n",
    "                        \"top_k\": {\"type\": \"integer\", \"description\": \"Number of results\", \"default\": 5},\n",
    "                    },\n",
    "                    \"required\": [\"query\"]\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "    \n",
    "    def build_system_prompt(\n",
    "        self, \n",
    "        config: EvaluationConfig,\n",
    "        user_task: str = \"\",\n",
    "        user_persona: str = \"\",\n",
    "        user_mission_objective: str = \"\"\n",
    "    ) -> tuple[str, Dict[str, str]]:\n",
    "        \"\"\"\n",
    "        Build system prompt following exact ChatService._build_conversation_context order.\n",
    "        Returns: (final_system_prompt, prompt_sources_dict)\n",
    "        \"\"\"\n",
    "        prompt_sections = []\n",
    "        prompt_sources = {\n",
    "            \"prompt_general\": None,\n",
    "            \"student_profile\": {},\n",
    "            \"specific_prompt\": None,\n",
    "        }\n",
    "        \n",
    "        # SECTION 1: General Prompt (highest priority)\n",
    "        prompt_general = config.prompt_general_override\n",
    "        if prompt_general is None:\n",
    "            prompt_general = self.chat_config.get(\"prompt_general\")\n",
    "        \n",
    "        if prompt_general:\n",
    "            prompt_sections.append(f\"# General Prompt\\n{prompt_general}\")\n",
    "            prompt_sources[\"prompt_general\"] = prompt_general\n",
    "        \n",
    "        # SECTION 2: Student Learning Profile (mid priority)\n",
    "        student_profile = []\n",
    "        \n",
    "        task = config.task_override if config.task_override else user_task\n",
    "        if task:\n",
    "            student_profile.append(f\"# Task\\n{task}\")\n",
    "            prompt_sources[\"student_profile\"][\"task\"] = task\n",
    "        \n",
    "        persona = config.persona_override if config.persona_override else user_persona\n",
    "        if persona:\n",
    "            student_profile.append(f\"# Persona\\n{persona}\")\n",
    "            prompt_sources[\"student_profile\"][\"persona\"] = persona\n",
    "        \n",
    "        mission_objective = config.mission_objective_override if config.mission_objective_override else user_mission_objective\n",
    "        if mission_objective:\n",
    "            student_profile.append(f\"# Mission Objective\\n{mission_objective}\")\n",
    "            prompt_sources[\"student_profile\"][\"mission_objective\"] = mission_objective\n",
    "        \n",
    "        if student_profile:\n",
    "            prompt_sections.append(\"## Student Learning Profile\\n\" + \"\\n\\n\".join(student_profile))\n",
    "        \n",
    "        # SECTION 3: Specific Prompt (lowest priority, from Prompt table)\n",
    "        if config.prompt_id_override:\n",
    "            specific_prompt = get_prompt_content(config.prompt_id_override)\n",
    "            if specific_prompt:\n",
    "                prompt_sections.append(f\"# Specific Prompt\\n{specific_prompt}\")\n",
    "                prompt_sources[\"specific_prompt\"] = specific_prompt\n",
    "        \n",
    "        system_prompt = \"\\n\\n\".join(prompt_sections) if prompt_sections else \"You are a helpful educational assistant.\"\n",
    "        \n",
    "        return system_prompt, prompt_sources\n",
    "    \n",
    "    async def _execute_refine_prompt(self, args: Dict[str, Any], print_steps: bool = False) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Execute refine_prompt tool - uses ChatConfig.prompt_refine as instruction.\n",
    "        THIS IS THE MOST CRITICAL PART - MUST ACTUALLY CALL LLM\n",
    "        \"\"\"\n",
    "        original_prompt = args.get(\"original_prompt\", \"\")\n",
    "        \n",
    "        if not original_prompt:\n",
    "            if print_steps:\n",
    "                print(f\"\\n      âŒ ERROR: Empty prompt provided\")\n",
    "            return {\n",
    "                \"original\": original_prompt,\n",
    "                \"refined\": original_prompt,\n",
    "                \"success\": False,\n",
    "                \"error\": \"Empty prompt provided\"\n",
    "            }\n",
    "        \n",
    "        try:\n",
    "            # CRITICAL: Get refine instruction from ChatConfig\n",
    "            refine_instruction = self.chat_config.get(\"prompt_refine\")\n",
    "            \n",
    "            if not refine_instruction:\n",
    "                refine_instruction = \"Refine the student's question to be more specific and clear for better search results.\"\n",
    "            \n",
    "            if print_steps:\n",
    "                print(f\"\\n      âœ… [STEP 1] Got refine instruction from ChatConfig\")\n",
    "                print(f\"      {'-'*70}\")\n",
    "                print(f\"      Instruction: {refine_instruction}\")\n",
    "                print(f\"      {'-'*70}\")\n",
    "                print(f\"\\n      âœ… [STEP 2] Building messages for LLM\")\n",
    "            \n",
    "            # Create messages for LLM refinement (THIS IS CRITICAL)\n",
    "            messages = [\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": refine_instruction\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": original_prompt\n",
    "                }\n",
    "            ]\n",
    "            \n",
    "            if print_steps:\n",
    "                print(f\"      System message: {messages[0]['content'][:80]}...\")\n",
    "                print(f\"      User message: {messages[1]['content']}\")\n",
    "                print(f\"\\n      âœ… [STEP 3] Calling OpenAI API with gpt-4.1-nano\")\n",
    "            \n",
    "            # CRITICAL: Call OpenAI API - this MUST execute and return actual LLM output\n",
    "            try:\n",
    "                response = client.chat.completions.create(\n",
    "                    model=\"gpt-4.1-nano\",  # Use this fast model like production\n",
    "                    messages=messages,\n",
    "                    temperature=0.7,\n",
    "                    max_tokens=300\n",
    "                )\n",
    "                \n",
    "                refined_prompt = response.choices[0].message.content\n",
    "                \n",
    "                if not refined_prompt:\n",
    "                    refined_prompt = original_prompt\n",
    "                \n",
    "                if print_steps:\n",
    "                    print(f\"      âœ… [STEP 4] Got response from OpenAI\")\n",
    "                    print(f\"      {'-'*70}\")\n",
    "                    print(f\"      Original: {original_prompt}\")\n",
    "                    print(f\"      Refined:  {refined_prompt}\")\n",
    "                    print(f\"      {'-'*70}\\n\")\n",
    "                \n",
    "                return {\n",
    "                    \"original\": original_prompt,\n",
    "                    \"refined\": refined_prompt,\n",
    "                    \"success\": True\n",
    "                }\n",
    "            \n",
    "            except Exception as api_error:\n",
    "                if print_steps:\n",
    "                    print(f\"      âŒ [STEP 3] API ERROR: {str(api_error)}\")\n",
    "                    print(f\"      Returning original unchanged (fallback)\\n\")\n",
    "                \n",
    "                # On API error, return original\n",
    "                return {\n",
    "                    \"original\": original_prompt,\n",
    "                    \"refined\": original_prompt,\n",
    "                    \"success\": False,\n",
    "                    \"error\": f\"API Error: {str(api_error)}\"\n",
    "                }\n",
    "        \n",
    "        except Exception as e:\n",
    "            if print_steps:\n",
    "                print(f\"      âŒ [STEP ?] UNEXPECTED ERROR: {str(e)}\")\n",
    "                print(f\"      Type: {type(e).__name__}\\n\")\n",
    "            \n",
    "            return {\n",
    "                \"original\": original_prompt,\n",
    "                \"refined\": original_prompt,\n",
    "                \"success\": False,\n",
    "                \"error\": f\"Unexpected error: {str(e)}\"\n",
    "            }\n",
    "    \n",
    "    async def _execute_semantic_search(self, args: Dict[str, Any], print_steps: bool = False) -> Dict[str, Any]:\n",
    "        \"\"\"Execute semantic search with detailed logging.\"\"\"\n",
    "        query = args.get(\"query\", \"\")\n",
    "        top_k = args.get(\"top_k\", self.chat_config.get(\"default_top_k\", 5))\n",
    "        \n",
    "        try:\n",
    "            results = semantic_search(query, top_k=top_k)\n",
    "            \n",
    "            if print_steps:\n",
    "                print(f\"\\n      [semantic_search RESULTS]\")\n",
    "                print(f\"      Query: {query}\")\n",
    "                print(f\"      Top-K: {top_k}\")\n",
    "                print(f\"      Found: {len(results)} documents\\n\")\n",
    "                for i, r in enumerate(results, 1):\n",
    "                    print(f\"      [{i}] {r['original_filename']} (page {r['page_number']}, similarity: {r['similarity_score']:.3f})\")\n",
    "                    print(f\"          {r['content'][:150]}...\\n\")\n",
    "            \n",
    "            return {\n",
    "                \"query\": query,\n",
    "                \"results\": [\n",
    "                    {\n",
    "                        \"content\": r.get(\"content\", \"\"),\n",
    "                        \"filename\": r.get(\"original_filename\"),\n",
    "                        \"page\": r.get(\"page_number\"),\n",
    "                        \"similarity\": r.get(\"similarity_score\"),\n",
    "                    }\n",
    "                    for r in results\n",
    "                ]\n",
    "            }\n",
    "        except Exception as e:\n",
    "            return {\"error\": str(e), \"query\": query}\n",
    "    \n",
    "    async def send_message_with_tools(\n",
    "        self,\n",
    "        user_message: str,\n",
    "        config: EvaluationConfig,\n",
    "        user_task: str = \"\",\n",
    "        user_persona: str = \"\",\n",
    "        user_mission_objective: str = \"\",\n",
    "        print_steps: bool = True\n",
    "    ) -> Dict[str, Any]:\n",
    "        \"\"\"Send message with tool calling - matches production flow.\"\"\"\n",
    "        \n",
    "        # Build system prompt with all layers\n",
    "        system_prompt, prompt_sources = self.build_system_prompt(\n",
    "            config, user_task, user_persona, user_mission_objective\n",
    "        )\n",
    "        \n",
    "        if print_steps:\n",
    "            print(f\"\\n{'='*70}\")\n",
    "            print(f\"ðŸ“‹ SYSTEM PROMPT CONSTRUCTION\")\n",
    "            print(f\"{'='*70}\")\n",
    "            print(system_prompt)\n",
    "            print(f\"{'='*70}\\n\")\n",
    "        \n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_message}\n",
    "        ]\n",
    "        \n",
    "        tools = self._get_tools()\n",
    "        \n",
    "        full_response = \"\"\n",
    "        tool_calls_made = []\n",
    "        iteration = 0\n",
    "        max_iterations = config.max_tool_iterations\n",
    "        \n",
    "        while iteration < max_iterations:\n",
    "            iteration += 1\n",
    "            print(f\"  [Iteration {iteration}/{max_iterations}]\", end=\" \")\n",
    "            \n",
    "            # Call OpenAI dengan tools\n",
    "            response = client.chat.completions.create(\n",
    "                model=config.model_name,\n",
    "                messages=messages,\n",
    "                tools=[{\"type\": \"function\", \"function\": t} for t in tools],\n",
    "                tool_choice=\"auto\",\n",
    "                temperature=config.temperature\n",
    "            )\n",
    "            \n",
    "            assistant_message = response.choices[0].message\n",
    "            \n",
    "            if assistant_message.tool_calls:\n",
    "                # Add assistant message with tool_calls to messages\n",
    "                tool_calls = assistant_message.tool_calls\n",
    "                messages.append({\n",
    "                    \"role\": \"assistant\",\n",
    "                    \"content\": assistant_message.content or \"\",\n",
    "                    \"tool_calls\": [\n",
    "                        {\n",
    "                            \"id\": tc.id,\n",
    "                            \"type\": \"function\",\n",
    "                            \"function\": {\n",
    "                                \"name\": tc.function.name,\n",
    "                                \"arguments\": tc.function.arguments\n",
    "                            }\n",
    "                        }\n",
    "                        for tc in tool_calls\n",
    "                    ]\n",
    "                })\n",
    "                \n",
    "                # Execute tools\n",
    "                for tool_call in tool_calls:\n",
    "                    print(f\"ðŸ”§ {tool_call.function.name}\", end=\" \")\n",
    "                    tool_name = tool_call.function.name\n",
    "                    try:\n",
    "                        tool_args = json.loads(tool_call.function.arguments)\n",
    "                        \n",
    "                        # Execute the appropriate tool with detailed logging\n",
    "                        if tool_name == \"refine_prompt\":\n",
    "                            result = await self._execute_refine_prompt(tool_args, print_steps=print_steps)\n",
    "                        elif tool_name == \"semantic_search\":\n",
    "                            result = await self._execute_semantic_search(tool_args, print_steps=print_steps)\n",
    "                        else:\n",
    "                            result = {\"error\": f\"Unknown tool: {tool_name}\"}\n",
    "                        \n",
    "                        # Add tool result to messages\n",
    "                        messages.append({\n",
    "                            \"role\": \"tool\",\n",
    "                            \"tool_call_id\": tool_call.id,\n",
    "                            \"content\": json.dumps(result)\n",
    "                        })\n",
    "                        \n",
    "                        tool_calls_made.append({\n",
    "                            \"name\": tool_name,\n",
    "                            \"args\": tool_args,\n",
    "                            \"result\": result,\n",
    "                        })\n",
    "                        \n",
    "                        print(f\"â†’ OK\", end=\" \")\n",
    "                    except Exception as e:\n",
    "                        print(f\"âœ— Error: {e}\", end=\" \")\n",
    "                \n",
    "                print()\n",
    "            else:\n",
    "                # No tool calls, we're done\n",
    "                full_response = assistant_message.content or \"\"\n",
    "                print(\"âœ“ Done\")\n",
    "                break\n",
    "        \n",
    "        return {\n",
    "            \"content\": full_response,\n",
    "            \"tool_calls\": tool_calls_made,\n",
    "            \"iteration\": iteration,\n",
    "            \"prompt_sources\": prompt_sources,\n",
    "        }\n",
    "    \n",
    "    async def send_message_stream(\n",
    "        self,\n",
    "        user_message: str,\n",
    "        config: EvaluationConfig,\n",
    "        user_task: str = \"\",\n",
    "        user_persona: str = \"\",\n",
    "        user_mission_objective: str = \"\",\n",
    "        print_steps: bool = True\n",
    "    ) -> Dict[str, Any]:\n",
    "        \"\"\"Send message without tools.\"\"\"\n",
    "        \n",
    "        # Build system prompt with all layers\n",
    "        system_prompt, prompt_sources = self.build_system_prompt(\n",
    "            config, user_task, user_persona, user_mission_objective\n",
    "        )\n",
    "        \n",
    "        if print_steps:\n",
    "            print(f\"\\n{'='*70}\")\n",
    "            print(f\"ðŸ“‹ SYSTEM PROMPT CONSTRUCTION\")\n",
    "            print(f\"{'='*70}\")\n",
    "            print(system_prompt)\n",
    "            print(f\"{'='*70}\\n\")\n",
    "        \n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_message}\n",
    "        ]\n",
    "        \n",
    "        response = client.chat.completions.create(\n",
    "            model=config.model_name,\n",
    "            messages=messages,\n",
    "            temperature=config.temperature\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            \"content\": response.choices[0].message.content or \"\",\n",
    "            \"tool_calls\": [],\n",
    "            \"iteration\": 1,\n",
    "            \"prompt_sources\": prompt_sources,\n",
    "        }\n",
    "\n",
    "print(\"âœ“ EvaluationChatService ready (with fixed refine_prompt execution)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d71a48",
   "metadata": {},
   "source": [
    "# EvaluationMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16361235",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ EvaluationMetrics ready\n"
     ]
    }
   ],
   "source": [
    "class EvaluationMetrics:\n",
    "    \"\"\"\n",
    "    Evaluation metrics for chat responses:\n",
    "    - BLEU: N-gram precision\n",
    "    - ROUGE-L: Longest common subsequence F1\n",
    "    - METEOR: Alignment-based with stemming\n",
    "    - BERTScore: Semantic similarity (Precision, Recall, F1)\n",
    "    \"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def bleu_score(reference: str, candidate: str, weights: tuple = (0.25, 0.25, 0.25, 0.25)) -> float:\n",
    "        \"\"\"\n",
    "        Calculate BLEU score (n-gram precision).\n",
    "        Range: [0, 1] where 1 is perfect match.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            reference_tokens = word_tokenize(reference.lower())\n",
    "            candidate_tokens = word_tokenize(candidate.lower())\n",
    "            smoothing_function = SmoothingFunction().method1\n",
    "            score = sentence_bleu(\n",
    "                [reference_tokens],\n",
    "                candidate_tokens,\n",
    "                weights=weights,\n",
    "                smoothing_function=smoothing_function\n",
    "            )\n",
    "            return float(score)\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: BLEU score calculation failed: {e}\")\n",
    "            return 0.0\n",
    "    \n",
    "    @staticmethod\n",
    "    def rouge_l_score(reference: str, candidate: str) -> float:\n",
    "        \"\"\"\n",
    "        Calculate ROUGE-L score (longest common subsequence F1).\n",
    "        Range: [0, 1] where 1 is perfect match.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            scorer = rouge_scorer.RougeScorer(['rougeL'], use_stemmer=True)\n",
    "            scores = scorer.score(reference, candidate)\n",
    "            return float(scores['rougeL'].fmeasure)\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: ROUGE-L calculation failed: {e}\")\n",
    "            return 0.0\n",
    "    \n",
    "    @staticmethod\n",
    "    def meteor_score(reference: str, candidate: str) -> float:\n",
    "        \"\"\"\n",
    "        Calculate METEOR score (alignment-based with stemming).\n",
    "        Range: [0, 1] where 1 is perfect match.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            reference_tokens = word_tokenize(reference.lower())\n",
    "            candidate_tokens = word_tokenize(candidate.lower())\n",
    "            score = meteor_score([reference_tokens], candidate_tokens)\n",
    "            return float(score)\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: METEOR calculation failed: {e}\")\n",
    "            return 0.0\n",
    "    \n",
    "    @staticmethod\n",
    "    def bert_score(reference: str, candidate: str, model_type: str = \"distilbert-base-uncased\") -> Dict[str, float]:\n",
    "        \"\"\"\n",
    "        Calculate BERTScore (semantic similarity).\n",
    "        Returns: {\"precision\": float, \"recall\": float, \"f1\": float}\n",
    "        Range: [0, 1] where 1 is perfect match.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            P, R, F1 = bert_score_fn([candidate], [reference], model_type=model_type, verbose=False)\n",
    "            return {\n",
    "                \"precision\": float(P[0]),\n",
    "                \"recall\": float(R[0]),\n",
    "                \"f1\": float(F1[0])\n",
    "            }\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: BERTScore calculation failed: {e}\")\n",
    "            return {\"precision\": 0.0, \"recall\": 0.0, \"f1\": 0.0}\n",
    "    \n",
    "    @staticmethod\n",
    "    def calculate_all_metrics(reference: str, candidate: str) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Calculate all evaluation metrics.\n",
    "        \"\"\"\n",
    "        print(\"  ðŸ“Š Computing metrics:\", end=\" \")\n",
    "        \n",
    "        metrics = {}\n",
    "        \n",
    "        print(\"BLEU\", end=\" \")\n",
    "        metrics[\"bleu\"] = EvaluationMetrics.bleu_score(reference, candidate)\n",
    "        \n",
    "        print(\"ROUGE-L\", end=\" \")\n",
    "        metrics[\"rouge_l\"] = EvaluationMetrics.rouge_l_score(reference, candidate)\n",
    "        \n",
    "        print(\"METEOR\", end=\" \")\n",
    "        metrics[\"meteor\"] = EvaluationMetrics.meteor_score(reference, candidate)\n",
    "        \n",
    "        print(\"BERTScore\", end=\" \")\n",
    "        metrics[\"bert_score\"] = EvaluationMetrics.bert_score(reference, candidate)\n",
    "        \n",
    "        # Calculate length ratio\n",
    "        ref_len = len(reference.split())\n",
    "        cand_len = len(candidate.split())\n",
    "        metrics[\"length_ratio\"] = cand_len / ref_len if ref_len > 0 else 0.0\n",
    "        \n",
    "        print(\"âœ“\")\n",
    "        \n",
    "        return metrics\n",
    "\n",
    "print(\"âœ“ EvaluationMetrics ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e3d49e",
   "metadata": {},
   "source": [
    "# EvaluationRunner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56f6f7be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ EvaluationRunner ready\n"
     ]
    }
   ],
   "source": [
    "class EvaluationRunner:\n",
    "    \"\"\"Orchestrates evaluation runs - matches production flow.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.chat_service = EvaluationChatService()\n",
    "    \n",
    "    async def evaluate_response(\n",
    "        self,\n",
    "        config: EvaluationConfig,\n",
    "        test_question: str,\n",
    "        reference_answer: str,\n",
    "        user_task: str = \"\",\n",
    "        user_persona: str = \"\",\n",
    "        user_mission_objective: str = \"\",\n",
    "        print_steps: bool = True,\n",
    "    ) -> Dict[str, Any]:\n",
    "        \"\"\"Evaluate a single response with full context.\"\"\"\n",
    "        \n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"ðŸ§ª Evaluation Run\")\n",
    "        print(f\"{'='*70}\")\n",
    "        print(f\"Model: {config.model_name}\")\n",
    "        print(f\"With Tools: {config.use_tools}\")\n",
    "        print(f\"Question: {test_question[:80]}...\")\n",
    "        \n",
    "        if user_task:\n",
    "            print(f\"Task: {user_task[:60]}...\")\n",
    "        if user_persona:\n",
    "            print(f\"Persona: {user_persona[:60]}...\")\n",
    "        if user_mission_objective:\n",
    "            print(f\"Mission: {user_mission_objective[:60]}...\")\n",
    "        \n",
    "        print(f\"{'-'*70}\")\n",
    "        \n",
    "        try:\n",
    "            print(f\"ðŸ“¤ Sending to {config.model_name}...\")\n",
    "            if config.use_tools:\n",
    "                if print_steps:\n",
    "                    print(\"\\nðŸ“‹ Evaluation Mode: WITH TOOLS (agentic loop)\\n\")\n",
    "                response = await self.chat_service.send_message_with_tools(\n",
    "                    user_message=test_question,\n",
    "                    config=config,\n",
    "                    user_task=user_task,\n",
    "                    user_persona=user_persona,\n",
    "                    user_mission_objective=user_mission_objective,\n",
    "                    print_steps=print_steps\n",
    "                )\n",
    "            else:\n",
    "                if print_steps:\n",
    "                    print(\"\\nðŸ“‹ Evaluation Mode: WITHOUT TOOLS (direct response)\\n\")\n",
    "                response = await self.chat_service.send_message_stream(\n",
    "                    user_message=test_question,\n",
    "                    config=config,\n",
    "                    user_task=user_task,\n",
    "                    user_persona=user_persona,\n",
    "                    user_mission_objective=user_mission_objective,\n",
    "                    print_steps=print_steps\n",
    "                )\n",
    "            \n",
    "            response_text = response.get(\"content\", \"\")\n",
    "            tool_calls = response.get(\"tool_calls\", [])\n",
    "            \n",
    "            print(f\"\\nâœ“ Response received ({len(response_text)} chars)\")\n",
    "            print(f\"  Tool calls made: {len(tool_calls)}\")\n",
    "            \n",
    "            if print_steps and tool_calls:\n",
    "                print(\"\\nðŸ”§ Tool Calls Summary:\")\n",
    "                for i, tc in enumerate(tool_calls, 1):\n",
    "                    print(f\"\\n  [{i}] Tool: {tc['name']}\")\n",
    "                    if tc['name'] == 'refine_prompt':\n",
    "                        print(f\"      Original: {tc['args'].get('original_prompt', '')[:100]}\")\n",
    "                        print(f\"      Refined:  {tc['result'].get('refined', '')[:100]}\")\n",
    "                    elif tc['name'] == 'semantic_search':\n",
    "                        print(f\"      Query: {tc['args'].get('query', '')}\")\n",
    "                        print(f\"      Results: {len(tc['result'].get('results', []))} documents found\")\n",
    "            \n",
    "            if print_steps:\n",
    "                print(f\"\\nðŸ“ Final Response from LLM:\")\n",
    "                print(f\"{'-'*70}\")\n",
    "                print(response_text[:500] + (\"...\" if len(response_text) > 500 else \"\"))\n",
    "                print(f\"{'-'*70}\\n\")\n",
    "            \n",
    "            metrics = EvaluationMetrics.calculate_all_metrics(reference_answer, response_text)\n",
    "            \n",
    "            result = {\n",
    "                \"timestamp\": datetime.now().isoformat(),\n",
    "                \"config\": asdict(config),\n",
    "                \"question\": test_question,\n",
    "                \"response\": response_text,\n",
    "                \"reference_answer\": reference_answer,\n",
    "                \"user_context\": {\n",
    "                    \"task\": user_task,\n",
    "                    \"persona\": user_persona,\n",
    "                    \"mission_objective\": user_mission_objective,\n",
    "                },\n",
    "                \"metrics\": metrics,\n",
    "                \"tool_calls\": tool_calls,\n",
    "            }\n",
    "            \n",
    "            print(f\"\\nðŸ“Š Results:\")\n",
    "            print(f\"  BLEU:       {metrics['bleu']:.4f}\")\n",
    "            print(f\"  ROUGE-L:    {metrics['rouge_l']:.4f}\")\n",
    "            print(f\"  METEOR:     {metrics['meteor']:.4f}\")\n",
    "            print(f\"  BERTScore:  {metrics['bert_score']['f1']:.4f}\")\n",
    "            \n",
    "            return result\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"âœ— Error: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            return {}\n",
    "\n",
    "print(\"âœ“ EvaluationRunner ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b77f1de",
   "metadata": {},
   "source": [
    "# Example Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de359c45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ðŸ’¡ To run evaluation with full prompt transparency:\n",
      "======================================================================\n",
      "result = await run_quick_evaluation()\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "async def run_quick_evaluation():\n",
    "    \"\"\"\n",
    "    Quick evaluation example with proper prompt context.\n",
    "    Tests the system with refine_prompt and semantic_search tools.\n",
    "    \"\"\"\n",
    "    \n",
    "    runner = EvaluationRunner()\n",
    "    \n",
    "    # User context (like a student)\n",
    "    user_task = \"Learn about machine learning fundamentals\"\n",
    "    user_persona = \"Beginner programmer with basic Python knowledge\"\n",
    "    user_mission_objective = \"Master neural networks and deep learning concepts\"\n",
    "    \n",
    "    # A somewhat vague question that would benefit from refinement\n",
    "    test_question = \"gimana machine learning itu?\"\n",
    "    \n",
    "    reference_answer = \"Machine learning is a field of artificial intelligence that enables systems to learn from data without being explicitly programmed.\"\n",
    "    \n",
    "    config = EvaluationConfig(\n",
    "        model_name=available_models[0]['name'] if available_models else \"gpt-4.1-nano\",\n",
    "        use_tools=True,\n",
    "        max_tool_iterations=3,\n",
    "    )\n",
    "    \n",
    "    result = await runner.evaluate_response(\n",
    "        config=config,\n",
    "        test_question=test_question,\n",
    "        reference_answer=reference_answer,\n",
    "        user_task=user_task,\n",
    "        user_persona=user_persona,\n",
    "        user_mission_objective=user_mission_objective,\n",
    "        print_steps=True  # Full transparency - show all prompts and tool execution\n",
    "    )\n",
    "    \n",
    "    return result\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ðŸ’¡ To run evaluation with full prompt transparency:\")\n",
    "print(\"=\"*70)\n",
    "print(\"result = await run_quick_evaluation()\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b320759",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ðŸ§ª Evaluation Run\n",
      "======================================================================\n",
      "Model: gpt-4.1-nano\n",
      "With Tools: True\n",
      "Question: gimana machine learning itu?...\n",
      "Task: Learn about machine learning fundamentals...\n",
      "Persona: Beginner programmer with basic Python knowledge...\n",
      "Mission: Master neural networks and deep learning concepts...\n",
      "----------------------------------------------------------------------\n",
      "ðŸ“¤ Sending to gpt-4.1-nano...\n",
      "\n",
      "ðŸ“‹ Evaluation Mode: WITH TOOLS (agentic loop)\n",
      "\n",
      "\n",
      "======================================================================\n",
      "ðŸ“‹ SYSTEM PROMPT CONSTRUCTION\n",
      "======================================================================\n",
      "# General Prompt\n",
      "You are a helpful learning assistant with access to two powerful tools:\\r                                  +\n",
      "\n",
      "## Student Learning Profile\n",
      "# Task\n",
      "Learn about machine learning fundamentals\n",
      "\n",
      "# Persona\n",
      "Beginner programmer with basic Python knowledge\n",
      "\n",
      "# Mission Objective\n",
      "Master neural networks and deep learning concepts\n",
      "======================================================================\n",
      "\n",
      "  [Iteration 1/3] ðŸ”§ refine_prompt \n",
      "      âœ… [STEP 1] Got refine instruction from ChatConfig\n",
      "      ----------------------------------------------------------------------\n",
      "      Instruction: Tingkatkan prompt student agar lebih jelas dan selalu mulai dengan kata RAJA\n",
      "      ----------------------------------------------------------------------\n",
      "\n",
      "      âœ… [STEP 2] Building messages for LLM\n",
      "      System message: Tingkatkan prompt student agar lebih jelas dan selalu mulai dengan kata RAJA...\n",
      "      User message: gimana machine learning itu?\n",
      "\n",
      "      âœ… [STEP 3] Calling OpenAI API with gpt-4.1-nano\n",
      "      âœ… [STEP 4] Got response from OpenAI\n",
      "      ----------------------------------------------------------------------\n",
      "      Original: gimana machine learning itu?\n",
      "      Refined:  RAJA, tolong jelaskan secara lengkap dan jelas apa itu machine learning, termasuk pengertiannya, cara kerjanya, dan contoh penggunaannya.\n",
      "      ----------------------------------------------------------------------\n",
      "\n",
      "â†’ OK \n",
      "  [Iteration 2/3] ðŸ”§ semantic_search \n",
      "      [semantic_search RESULTS]\n",
      "      Query: Pengertian machine learning, cara kerja, dan contoh penggunaannya\n",
      "      Top-K: 5\n",
      "      Found: 5 documents\n",
      "\n",
      "      [1] 4b tts-id v2.pdf (page 1, similarity: 0.359)\n",
      "          Sintesis Bentuk Gelombang Pemrosesan Bahasa Lisan Fakultas Ilmu Komputer Universitas Indonesia Semester Gasal 2024/2025 Referensi â–ª TTS Waveform Synth...\n",
      "\n",
      "      [2] 4b tts-id v2.pdf (page 57, similarity: 0.354)\n",
      "          unit (tidak seperti sintesis diphone) tidak dapat mengubah penekanan. â—‹ Seleksi unit memberikan hasil yang bagus (tetapi mungkin tidak sepenuhnya bena...\n",
      "\n",
      "      [3] 4b tts-id v2.pdf (page 11, similarity: 0.308)\n",
      "          Ekspresi 1 2 3 4 5 o Seberapa baik intonasi sesuai dengan substansi ucapan? A/B testing â€¢ Menggunakan pilihan yang bersumber dari banyak orang untuk m...\n",
      "\n",
      "      [4] 4b tts-id v2.pdf (page 27, similarity: 0.305)\n",
      "          aksen Hasilkan: â— Waveform 26 F0 Generation â— Berdasarkan aturan â— Menggunakan regresi linear atau machine learning â— Beberapa batasan: â—‹ Berdasarkan ...\n",
      "\n",
      "      [5] 4b tts-id v2.pdf (page 40, similarity: 0.278)\n",
      "          â—‹ Pemrosesan sinyal tetap diperlukan untuk memodifikasi durasi â—‹ Data sumber masih kurang alami â—‹ Unit terlalu kecil; tidak dapat menangani efek spesi...\n",
      "\n",
      "â†’ OK ðŸ”§ semantic_search \n",
      "      [semantic_search RESULTS]\n",
      "      Query: machine learning fundamentals, how it works, examples\n",
      "      Top-K: 5\n",
      "      Found: 5 documents\n",
      "\n",
      "      [1] 5a dialog-systems-en v2.pdf (page 55, similarity: 0.277)\n",
      "          Frame-based dialog architecture â€¢ The dialog-state architecture Dialogue-State or Belief-State Architecture A more sophisticated version of the frame-...\n",
      "\n",
      "      [2] 5a dialog-systems-en v2.pdf (page 61, similarity: 0.277)\n",
      "          classifier for Domain/Intent. Use sequence model to tag words/phrases with slot name â— Input: features like word N-grams â— Output: DOMAIN: AIRLINE INT...\n",
      "\n",
      "      [3] 4b tts-id v2.pdf (page 57, similarity: 0.271)\n",
      "          unit (tidak seperti sintesis diphone) tidak dapat mengubah penekanan. â—‹ Seleksi unit memberikan hasil yang bagus (tetapi mungkin tidak sepenuhnya bena...\n",
      "\n",
      "      [4] 4b tts-id v2.pdf (page 1, similarity: 0.269)\n",
      "          Sintesis Bentuk Gelombang Pemrosesan Bahasa Lisan Fakultas Ilmu Komputer Universitas Indonesia Semester Gasal 2024/2025 Referensi â–ª TTS Waveform Synth...\n",
      "\n",
      "      [5] 5a dialog-systems-en v2.pdf (page 76, similarity: 0.235)\n",
      "          also awkward and increases the length of the conversation (Danieli and Gerbino 1995, Walker et al. 1998). Rejection Iâ€™m sorry, I didnâ€™t understand tha...\n",
      "\n",
      "â†’ OK \n",
      "  [Iteration 3/3] âœ“ Done\n",
      "\n",
      "âœ“ Response received (993 chars)\n",
      "  Tool calls made: 3\n",
      "\n",
      "ðŸ”§ Tool Calls Summary:\n",
      "\n",
      "  [1] Tool: refine_prompt\n",
      "      Original: gimana machine learning itu?\n",
      "      Refined:  RAJA, tolong jelaskan secara lengkap dan jelas apa itu machine learning, termasuk pengertiannya, car\n",
      "\n",
      "  [2] Tool: semantic_search\n",
      "      Query: Pengertian machine learning, cara kerja, dan contoh penggunaannya\n",
      "      Results: 5 documents found\n",
      "\n",
      "  [3] Tool: semantic_search\n",
      "      Query: machine learning fundamentals, how it works, examples\n",
      "      Results: 5 documents found\n",
      "\n",
      "ðŸ“ Final Response from LLM:\n",
      "----------------------------------------------------------------------\n",
      "Machine learning adalah cabang dari kecerdasan buatan (AI) yang memungkinkan komputer belajar dari data dan pengalaman tanpa diprogram secara eksplisit untuk setiap tugas. Dengan kata lain, komputer menggunakan algoritma dan model statistik untuk mengenali pola dalam data, lalu membuat prediksi atau keputusan berdasarkan pola tersebut.\n",
      "\n",
      "Cara kerja machine learning secara umum meliputi beberapa langkah utama:\n",
      "1. Mengumpulkan data yang relevan.\n",
      "2. Melatih model menggunakan data tersebut agar dapat...\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "  ðŸ“Š Computing metrics: BLEU ROUGE-L METEOR BERTScore âœ“\n",
      "\n",
      "ðŸ“Š Results:\n",
      "  BLEU:       0.0029\n",
      "  ROUGE-L:    0.0523\n",
      "  METEOR:     0.0744\n",
      "  BERTScore:  0.5553\n"
     ]
    }
   ],
   "source": [
    "result = await run_quick_evaluation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "709d8d51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'timestamp': '2025-12-30T15:01:20.206466',\n",
       " 'config': {'model_name': 'gpt-4.1-nano',\n",
       "  'use_tools': True,\n",
       "  'with_rag': True,\n",
       "  'max_tool_iterations': 3,\n",
       "  'temperature': 0.7,\n",
       "  'prompt_general_override': None,\n",
       "  'task_override': None,\n",
       "  'persona_override': None,\n",
       "  'mission_objective_override': None,\n",
       "  'prompt_id_override': None},\n",
       " 'question': 'gimana machine learning itu?',\n",
       " 'response': 'Machine learning adalah cabang dari kecerdasan buatan yang memungkinkan komputer belajar dari data dan pengalaman tanpa diprogram secara eksplisit. Dengan menggunakan algoritma dan model statistik, machine learning dapat mengenali pola, membuat prediksi, dan mengambil keputusan berdasarkan data yang diberikan.  \\n\\nContoh aplikasi machine learning dalam kehidupan sehari-hari meliputi:\\n- Sistem rekomendasi seperti yang digunakan oleh Netflix dan Amazon untuk menyarankan film atau produk.\\n- Asisten virtual seperti Siri, Google Assistant, dan Alexa yang memahami perintah suara dan merespons.\\n- Pengklasifikasian email spam dan bukan spam.\\n- Pengenalan wajah dan pengenalan suara.\\n- Diagnosa medis berbasis data pasien.\\n\\nApakah Anda ingin penjelasan lebih mendalam tentang cara kerja machine learning atau contoh spesifik lainnya?',\n",
       " 'reference_answer': 'Machine learning is a field of artificial intelligence that enables systems to learn from data without being explicitly programmed.',\n",
       " 'user_context': {'task': 'Learn about machine learning fundamentals',\n",
       "  'persona': 'Beginner programmer with basic Python knowledge',\n",
       "  'mission_objective': 'Master neural networks and deep learning concepts'},\n",
       " 'metrics': {'bleu': 0.0036213111160275494,\n",
       "  'rouge_l': 0.06349206349206349,\n",
       "  'meteor': 0.12196721311475411,\n",
       "  'bert_score': {'precision': 0.5150566697120667,\n",
       "   'recall': 0.6554932594299316,\n",
       "   'f1': 0.5768505334854126},\n",
       "  'length_ratio': 5.842105263157895},\n",
       " 'tool_calls': [{'name': 'refine_prompt',\n",
       "   'args': {'original_prompt': 'gimana machine learning itu?'},\n",
       "   'result': {'original': 'gimana machine learning itu?',\n",
       "    'refined': 'RAJA, tolong jelaskan apa itu machine learning secara sederhana dan lengkap agar saya bisa memahami konsep dasarnya.',\n",
       "    'success': True}},\n",
       "  {'name': 'semantic_search',\n",
       "   'args': {'query': 'pengertian machine learning secara lengkap dan sederhana'},\n",
       "   'result': {'query': 'pengertian machine learning secara lengkap dan sederhana',\n",
       "    'results': [{'content': 'unit (tidak seperti sintesis diphone) tidak dapat mengubah penekanan. â—‹ Seleksi unit memberikan hasil yang bagus (tetapi mungkin tidak sepenuhnya benar). Sintesis bentuk gelombang: ikhtisar â€¢ Sintesis berbasis forman â€¢ Sintesis konkatenatif â€¢ Sintesis parametrik â€¢ Membangun sistem teks-ke-ucapan Pertanyaan kunci dalam sintesis parametrik â€¢ Parameter apa yang kita prediksi? o Biasanya MFCC untuk spektrum, log F0, voicing/eksitasi â€¢ Bagaimana kita menggabungkannya (vocoding)? o Parameterisasi yang',\n",
       "      'filename': '4b tts-id v2.pdf',\n",
       "      'page': 57,\n",
       "      'similarity': 0.40061135740121034},\n",
       "     {'content': 'Sintesis Bentuk Gelombang Pemrosesan Bahasa Lisan Fakultas Ilmu Komputer Universitas Indonesia Semester Gasal 2024/2025 Referensi â–ª TTS Waveform Synthesis â€“ Andrew Maas â–ª Text-to-Speech Synthesis â€“ OndÅ™ej DuÅ¡ek â–ª Speech Synthesis â€“ Preethi Jyothi â–ª https://speechprocessingbook.aalto.fi/ Sintesis bentuk gelombang: ikhtisar â€¢ Membangun sistem teks-ke-ucapan â€¢ Sintesis berbasis forman â€¢ Sintesis konkatenatif â€¢ Sintesis Difone â€¢ Sintesis seleksi unit â€¢ Sintesis parametrik 4 Dua Tahap dalam Sintesis ',\n",
       "      'filename': '4b tts-id v2.pdf',\n",
       "      'page': 1,\n",
       "      'similarity': 0.3671427581587243},\n",
       "     {'content': 'aksen Hasilkan: â— Waveform 26 F0 Generation â— Berdasarkan aturan â— Menggunakan regresi linear atau machine learning â— Beberapa batasan: â—‹ Berdasarkan aksen dan batas-batas kalimat â—‹ F0 menurun secara bertahap selama suatu ucapan (â€œdeclinationâ€) 27 F0 Generation by Rule â— Hasilkan daftar titik target F0 untuk setiap suku kata. Misalnya: â— Hasilkan aksen sederhana H* \"hat\" (nilai F0 tetap spesifik untuk pembicara) dengan 3 titik pitch: [110, 140, 100] â—‹ Modified by â—‹ gender, â—‹ declination, â—‹ end o',\n",
       "      'filename': '4b tts-id v2.pdf',\n",
       "      'page': 27,\n",
       "      'similarity': 0.3245444519068661},\n",
       "     {'content': 'Ekspresi 1 2 3 4 5 o Seberapa baik intonasi sesuai dengan substansi ucapan? A/B testing â€¢ Menggunakan pilihan yang bersumber dari banyak orang untuk memperoleh preferensi langsung Ucapan 1 Ucapan 2 Ucapan manakah yang lebih Anda sukai? (Yang mana yang lebih mudah dipahami dan terdengar lebih alami) 1 2 Diagnostic rhyme test (DRT) â€¢ Manusia melakukan identifikasi pilihan mendengarkan antara dua kata yang berbeda dengan satu fitur fonetik o Suara, nasalitas, sutensi, desisan â€¢ 96 pasangan rima â€¢ %',\n",
       "      'filename': '4b tts-id v2.pdf',\n",
       "      'page': 11,\n",
       "      'similarity': 0.3220679639405146},\n",
       "     {'content': 'â—‹ Pemrosesan sinyal tetap diperlukan untuk memodifikasi durasi â—‹ Data sumber masih kurang alami â—‹ Unit terlalu kecil; tidak dapat menangani efek spesifik kata, dll. 40 Problems with Diphone Synthesis â— Metode pemrosesan sinyal seperti TD-PSOLA meninggalkan artefak, membuat suara terdengar tidak alami. â— Sintesis diphone hanya menangkap efek lokal. â—‹ Namun, ada banyak efek global lainnya (struktur suku kata, pola stress, efek di level kata). Sintesis bentuk gelombang: ikhtisar â€¢ Membangun sistem ',\n",
       "      'filename': '4b tts-id v2.pdf',\n",
       "      'page': 40,\n",
       "      'similarity': 0.30180552190947035}]}},\n",
       "  {'name': 'semantic_search',\n",
       "   'args': {'query': 'contoh aplikasi machine learning dalam kehidupan sehari-hari'},\n",
       "   'result': {'query': 'contoh aplikasi machine learning dalam kehidupan sehari-hari',\n",
       "    'results': [{'content': 'Sintesis Bentuk Gelombang Pemrosesan Bahasa Lisan Fakultas Ilmu Komputer Universitas Indonesia Semester Gasal 2024/2025 Referensi â–ª TTS Waveform Synthesis â€“ Andrew Maas â–ª Text-to-Speech Synthesis â€“ OndÅ™ej DuÅ¡ek â–ª Speech Synthesis â€“ Preethi Jyothi â–ª https://speechprocessingbook.aalto.fi/ Sintesis bentuk gelombang: ikhtisar â€¢ Membangun sistem teks-ke-ucapan â€¢ Sintesis berbasis forman â€¢ Sintesis konkatenatif â€¢ Sintesis Difone â€¢ Sintesis seleksi unit â€¢ Sintesis parametrik 4 Dua Tahap dalam Sintesis ',\n",
       "      'filename': '4b tts-id v2.pdf',\n",
       "      'page': 1,\n",
       "      'similarity': 0.4255361733552548},\n",
       "     {'content': 'unit (tidak seperti sintesis diphone) tidak dapat mengubah penekanan. â—‹ Seleksi unit memberikan hasil yang bagus (tetapi mungkin tidak sepenuhnya benar). Sintesis bentuk gelombang: ikhtisar â€¢ Sintesis berbasis forman â€¢ Sintesis konkatenatif â€¢ Sintesis parametrik â€¢ Membangun sistem teks-ke-ucapan Pertanyaan kunci dalam sintesis parametrik â€¢ Parameter apa yang kita prediksi? o Biasanya MFCC untuk spektrum, log F0, voicing/eksitasi â€¢ Bagaimana kita menggabungkannya (vocoding)? o Parameterisasi yang',\n",
       "      'filename': '4b tts-id v2.pdf',\n",
       "      'page': 57,\n",
       "      'similarity': 0.4215284097821499},\n",
       "     {'content': 'Ekspresi 1 2 3 4 5 o Seberapa baik intonasi sesuai dengan substansi ucapan? A/B testing â€¢ Menggunakan pilihan yang bersumber dari banyak orang untuk memperoleh preferensi langsung Ucapan 1 Ucapan 2 Ucapan manakah yang lebih Anda sukai? (Yang mana yang lebih mudah dipahami dan terdengar lebih alami) 1 2 Diagnostic rhyme test (DRT) â€¢ Manusia melakukan identifikasi pilihan mendengarkan antara dua kata yang berbeda dengan satu fitur fonetik o Suara, nasalitas, sutensi, desisan â€¢ 96 pasangan rima â€¢ %',\n",
       "      'filename': '4b tts-id v2.pdf',\n",
       "      'page': 11,\n",
       "      'similarity': 0.39257705638035717},\n",
       "     {'content': 'aksen Hasilkan: â— Waveform 26 F0 Generation â— Berdasarkan aturan â— Menggunakan regresi linear atau machine learning â— Beberapa batasan: â—‹ Berdasarkan aksen dan batas-batas kalimat â—‹ F0 menurun secara bertahap selama suatu ucapan (â€œdeclinationâ€) 27 F0 Generation by Rule â— Hasilkan daftar titik target F0 untuk setiap suku kata. Misalnya: â— Hasilkan aksen sederhana H* \"hat\" (nilai F0 tetap spesifik untuk pembicara) dengan 3 titik pitch: [110, 140, 100] â—‹ Modified by â—‹ gender, â—‹ declination, â—‹ end o',\n",
       "      'filename': '4b tts-id v2.pdf',\n",
       "      'page': 27,\n",
       "      'similarity': 0.37661451107749266},\n",
       "     {'content': 'â—‹ Pemrosesan sinyal tetap diperlukan untuk memodifikasi durasi â—‹ Data sumber masih kurang alami â—‹ Unit terlalu kecil; tidak dapat menangani efek spesifik kata, dll. 40 Problems with Diphone Synthesis â— Metode pemrosesan sinyal seperti TD-PSOLA meninggalkan artefak, membuat suara terdengar tidak alami. â— Sintesis diphone hanya menangkap efek lokal. â—‹ Namun, ada banyak efek global lainnya (struktur suku kata, pola stress, efek di level kata). Sintesis bentuk gelombang: ikhtisar â€¢ Membangun sistem ',\n",
       "      'filename': '4b tts-id v2.pdf',\n",
       "      'page': 40,\n",
       "      'similarity': 0.3537701970211527}]}}]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
